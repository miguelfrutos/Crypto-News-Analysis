{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine_Tuning_FinBERT_Strenght.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23a2c23-4e64-4dc1-a574-13a8d018d9c2"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast, AutoModelForSequenceClassification\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# specify GPU\n",
        "#device = torch.device(\"cuda\")"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwJrQFQgN_BE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "57f4af2d-a752-444f-9ca8-7641539fe5d3"
      },
      "source": [
        "df = pd.read_csv(\"strength_score_with_news.csv\")\n",
        "df.tail()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index                                               news  strength\n",
              "989   2403  Stable +30% BTCÂs monthly with FBC13  - Inter...         0\n",
              "990   2407  Celsius and Horizen to Build Fully Decentraliz...         0\n",
              "991   2437  +1095% BTC per year with RJV12, scam or revolu...         0\n",
              "992   2438  Gambling for a good cause Â CryptoSlots donat...         0\n",
              "993   2439       Litecoin, The Chinese Alternative to Bitcoin         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96a51564-499d-4709-a638-d67abdc673a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>news</th>\n",
              "      <th>strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>2403</td>\n",
              "      <td>Stable +30% BTCÂs monthly with FBC13  - Inter...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>2407</td>\n",
              "      <td>Celsius and Horizen to Build Fully Decentraliz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>2437</td>\n",
              "      <td>+1095% BTC per year with RJV12, scam or revolu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>2438</td>\n",
              "      <td>Gambling for a good cause Â CryptoSlots donat...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>2439</td>\n",
              "      <td>Litecoin, The Chinese Alternative to Bitcoin</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96a51564-499d-4709-a638-d67abdc673a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96a51564-499d-4709-a638-d67abdc673a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96a51564-499d-4709-a638-d67abdc673a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['news','strength']]\n",
        "df = df.rename(columns={\"news\":\"text\"})\n",
        "df = df.rename(columns={\"strength\":\"label\"})\n",
        "cols = df.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df = df[cols]\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qemWmJxfFsgH",
        "outputId": "e1590479-fcb9-4053-f55d-997d77c6e11d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     label                                               text\n",
              "989      0  Stable +30% BTCÂs monthly with FBC13  - Inter...\n",
              "990      0  Celsius and Horizen to Build Fully Decentraliz...\n",
              "991      0  +1095% BTC per year with RJV12, scam or revolu...\n",
              "992      0  Gambling for a good cause Â CryptoSlots donat...\n",
              "993      0       Litecoin, The Chinese Alternative to Bitcoin"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa30f204-6d1c-434c-ba3c-b4c7813058e8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>0</td>\n",
              "      <td>Stable +30% BTCÂs monthly with FBC13  - Inter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>990</th>\n",
              "      <td>0</td>\n",
              "      <td>Celsius and Horizen to Build Fully Decentraliz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>0</td>\n",
              "      <td>+1095% BTC per year with RJV12, scam or revolu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>992</th>\n",
              "      <td>0</td>\n",
              "      <td>Gambling for a good cause Â CryptoSlots donat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>993</th>\n",
              "      <td>0</td>\n",
              "      <td>Litecoin, The Chinese Alternative to Bitcoin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa30f204-6d1c-434c-ba3c-b4c7813058e8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa30f204-6d1c-434c-ba3c-b4c7813058e8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa30f204-6d1c-434c-ba3c-b4c7813058e8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzPPOrVQWiW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bbdbf6e-e6b4-4f37-f072-a7b7506d5af5"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(994, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZJpKKPZXOnl",
        "outputId": "d6fc599d-2940-44ef-cf23-30441eb0e11a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    515\n",
              "1    479\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlHuusJMXPyG",
        "outputId": "17a5407c-4eea-476b-a932-96c73fc16a01"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "695"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f77d26d-a8b1-4884-c8fe-7be7754192fd"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('ProsusAI/finbert')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('ProsusAI/finbert')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAH73n39PHLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248f9925-0996-4d24-8ac1-f0e75393bb85"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwbpeN_PMiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "97d94428-dfb3-416f-e6b1-dd9c4fd30896"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f31cfb6d990>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "max_seq_len = 40"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28808d06-56fe-43f1-c409-0999d92a8934"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "source": [
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask,return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "#model = model.to(device)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10840315-f9ad-4bb6-8cfa-1540a0f16ee4"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izY5xH5eR7Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed26d7bb-a500-4323-b7cd-6aa29110112d"
      },
      "source": [
        "#Rebalnce the Dataset\n",
        "\n",
        "class_wts= compute_class_weight(class_weight = \"balanced\",classes = np.unique(train_labels),y=train_labels)\n",
        "class_weights = dict(zip(np.unique(train_labels), class_wts))\n",
        "class_weights\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.96527778 1.03731343]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "#weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    #batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    #batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1USGTntS3TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8154f35d-205f-4ca6-d086-387687ba6ac7"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights_strenght.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.786\n",
            "Validation Loss: 0.753\n",
            "\n",
            " Epoch 2 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.750\n",
            "Validation Loss: 0.716\n",
            "\n",
            " Epoch 3 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.730\n",
            "Validation Loss: 0.719\n",
            "\n",
            " Epoch 4 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.695\n",
            "Validation Loss: 0.707\n",
            "\n",
            " Epoch 5 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.710\n",
            "Validation Loss: 0.738\n",
            "\n",
            " Epoch 6 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.708\n",
            "Validation Loss: 0.716\n",
            "\n",
            " Epoch 7 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.701\n",
            "Validation Loss: 0.680\n",
            "\n",
            " Epoch 8 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.690\n",
            "Validation Loss: 0.773\n",
            "\n",
            " Epoch 9 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.700\n",
            "Validation Loss: 0.677\n",
            "\n",
            " Epoch 10 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.692\n",
            "Validation Loss: 0.676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacxUyizS8d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e9f3ec-d87a-49c4-96de-f790d2467ed1"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights_strenght.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Predictions for Val Data"
      ],
      "metadata": {
        "id": "7YryIjX7yCRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for val data\n",
        "with torch.no_grad():\n",
        "  logits = model(val_seq, val_mask)\n",
        "  probs = F.softmax(logits, dim=1) # assuming logits has the shape [batch_size, nb_classes]\n",
        "  preds = logits.detach().cpu().numpy()"
      ],
      "metadata": {
        "id": "s1PaJi-8j75Y"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability of each of the classes [normal,abnormal]\n",
        "probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX9eS7injmxb",
        "outputId": "879f00a4-4677-47db-fc6c-a7a6204d582f"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2089, 0.7911],\n",
              "        [0.5400, 0.4600],\n",
              "        [0.6636, 0.3364],\n",
              "        [0.5676, 0.4324],\n",
              "        [0.4493, 0.5507],\n",
              "        [0.5716, 0.4284],\n",
              "        [0.6143, 0.3857],\n",
              "        [0.4869, 0.5131],\n",
              "        [0.5885, 0.4115],\n",
              "        [0.5893, 0.4107],\n",
              "        [0.3545, 0.6455],\n",
              "        [0.5474, 0.4526],\n",
              "        [0.6378, 0.3622],\n",
              "        [0.4638, 0.5362],\n",
              "        [0.5738, 0.4262],\n",
              "        [0.6110, 0.3890],\n",
              "        [0.5473, 0.4527],\n",
              "        [0.4653, 0.5347],\n",
              "        [0.1048, 0.8952],\n",
              "        [0.5709, 0.4291],\n",
              "        [0.5020, 0.4980],\n",
              "        [0.5020, 0.4980],\n",
              "        [0.5806, 0.4194],\n",
              "        [0.4824, 0.5176],\n",
              "        [0.5124, 0.4876],\n",
              "        [0.5983, 0.4017],\n",
              "        [0.5337, 0.4663],\n",
              "        [0.6694, 0.3306],\n",
              "        [0.5391, 0.4609],\n",
              "        [0.4517, 0.5483],\n",
              "        [0.4576, 0.5424],\n",
              "        [0.5901, 0.4099],\n",
              "        [0.5659, 0.4341],\n",
              "        [0.6171, 0.3829],\n",
              "        [0.4946, 0.5054],\n",
              "        [0.4508, 0.5492],\n",
              "        [0.4671, 0.5329],\n",
              "        [0.7077, 0.2923],\n",
              "        [0.5377, 0.4623],\n",
              "        [0.3635, 0.6365],\n",
              "        [0.5993, 0.4007],\n",
              "        [0.4635, 0.5365],\n",
              "        [0.6671, 0.3329],\n",
              "        [0.6978, 0.3022],\n",
              "        [0.5832, 0.4168],\n",
              "        [0.1083, 0.8917],\n",
              "        [0.6559, 0.3441],\n",
              "        [0.4660, 0.5340],\n",
              "        [0.4841, 0.5159],\n",
              "        [0.4996, 0.5004],\n",
              "        [0.1107, 0.8893],\n",
              "        [0.6185, 0.3815],\n",
              "        [0.6307, 0.3693],\n",
              "        [0.5150, 0.4850],\n",
              "        [0.4652, 0.5348],\n",
              "        [0.4628, 0.5372],\n",
              "        [0.5117, 0.4883],\n",
              "        [0.6175, 0.3825],\n",
              "        [0.4730, 0.5270],\n",
              "        [0.4924, 0.5076],\n",
              "        [0.4916, 0.5084],\n",
              "        [0.6658, 0.3342],\n",
              "        [0.6598, 0.3402],\n",
              "        [0.5426, 0.4574],\n",
              "        [0.6575, 0.3425],\n",
              "        [0.5138, 0.4862],\n",
              "        [0.6311, 0.3689],\n",
              "        [0.5907, 0.4093],\n",
              "        [0.4840, 0.5160],\n",
              "        [0.6687, 0.3313],\n",
              "        [0.6351, 0.3649],\n",
              "        [0.6528, 0.3472],\n",
              "        [0.4408, 0.5592],\n",
              "        [0.6539, 0.3461],\n",
              "        [0.5179, 0.4821],\n",
              "        [0.4339, 0.5661],\n",
              "        [0.5005, 0.4995],\n",
              "        [0.6773, 0.3227],\n",
              "        [0.4414, 0.5586],\n",
              "        [0.6308, 0.3692],\n",
              "        [0.6464, 0.3536],\n",
              "        [0.5120, 0.4880],\n",
              "        [0.4491, 0.5509],\n",
              "        [0.4575, 0.5425],\n",
              "        [0.5675, 0.4325],\n",
              "        [0.4500, 0.5500],\n",
              "        [0.6820, 0.3180],\n",
              "        [0.6342, 0.3658],\n",
              "        [0.4945, 0.5055],\n",
              "        [0.4456, 0.5544],\n",
              "        [0.5939, 0.4061],\n",
              "        [0.4661, 0.5339],\n",
              "        [0.5301, 0.4699],\n",
              "        [0.5536, 0.4464],\n",
              "        [0.4817, 0.5183],\n",
              "        [0.6385, 0.3615],\n",
              "        [0.6384, 0.3616],\n",
              "        [0.4499, 0.5501],\n",
              "        [0.5322, 0.4678],\n",
              "        [0.6704, 0.3296],\n",
              "        [0.6677, 0.3323],\n",
              "        [0.6035, 0.3965],\n",
              "        [0.4622, 0.5378],\n",
              "        [0.4677, 0.5323],\n",
              "        [0.5124, 0.4876],\n",
              "        [0.3916, 0.6084],\n",
              "        [0.1051, 0.8949],\n",
              "        [0.1810, 0.8190],\n",
              "        [0.6382, 0.3618],\n",
              "        [0.6319, 0.3681],\n",
              "        [0.3184, 0.6816],\n",
              "        [0.4832, 0.5168],\n",
              "        [0.6743, 0.3257],\n",
              "        [0.7540, 0.2460],\n",
              "        [0.5346, 0.4654],\n",
              "        [0.1666, 0.8334],\n",
              "        [0.4382, 0.5618],\n",
              "        [0.5945, 0.4055],\n",
              "        [0.6443, 0.3557],\n",
              "        [0.0870, 0.9130],\n",
              "        [0.4841, 0.5159],\n",
              "        [0.1687, 0.8313],\n",
              "        [0.6502, 0.3498],\n",
              "        [0.5423, 0.4577],\n",
              "        [0.4290, 0.5710],\n",
              "        [0.5543, 0.4457],\n",
              "        [0.5566, 0.4434],\n",
              "        [0.5052, 0.4948],\n",
              "        [0.5895, 0.4105],\n",
              "        [0.4688, 0.5312],\n",
              "        [0.3503, 0.6497],\n",
              "        [0.6663, 0.3337],\n",
              "        [0.5233, 0.4767],\n",
              "        [0.6034, 0.3966],\n",
              "        [0.5526, 0.4474],\n",
              "        [0.5534, 0.4466],\n",
              "        [0.6514, 0.3486],\n",
              "        [0.5222, 0.4778],\n",
              "        [0.6543, 0.3457],\n",
              "        [0.5385, 0.4615],\n",
              "        [0.6582, 0.3418],\n",
              "        [0.5900, 0.4100],\n",
              "        [0.6424, 0.3576],\n",
              "        [0.4780, 0.5220],\n",
              "        [0.6270, 0.3730],\n",
              "        [0.5761, 0.4239],\n",
              "        [0.6390, 0.3610],\n",
              "        [0.6664, 0.3336],\n",
              "        [0.4607, 0.5393]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions based on the highest probabilities\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_RNuJQCky2E",
        "outputId": "7833060e-47ec-4850-b30d-7f80d28f4462"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model's performance\n",
        "print(classification_report(val_y, preds))\n",
        "print(f\"roc_auc:{roc_auc_score(val_y, probs[:,1])}\")"
      ],
      "metadata": {
        "id": "WuUP1jixvd-7",
        "outputId": "24af35c9-7ea1-47c1-f8f0-9d52d7aa6809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.68      0.60        77\n",
            "           1       0.54      0.40      0.46        72\n",
            "\n",
            "    accuracy                           0.54       149\n",
            "   macro avg       0.54      0.54      0.53       149\n",
            "weighted avg       0.54      0.54      0.53       149\n",
            "\n",
            "roc_auc:0.5793650793650793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "source": [
        "# get predictions for val data\n",
        "with torch.no_grad():\n",
        "  logits = model(test_seq, test_mask)\n",
        "  probs = F.softmax(logits, dim=1) # assuming logits has the shape [batch_size, nb_classes]\n",
        "  preds = logits.detach().cpu().numpy()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability of each of the classes [neutral,positive,negative]\n",
        "probs"
      ],
      "metadata": {
        "id": "tDukz78YiLe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions based on the highest probabilities\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ53XoUXobAL",
        "outputId": "75f2b104-ffd4-4895-ef4a-d9f7a5c11811"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc17f33e-7f60-42f3-f265-641d0cdc8b26"
      },
      "source": [
        "# model's performance\n",
        "# model's performance\n",
        "print(classification_report(test_y, preds))\n",
        "print(f\"roc_auc:{roc_auc_score(test_y, probs[:,1])}\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.64      0.55        78\n",
            "           1       0.38      0.24      0.29        72\n",
            "\n",
            "    accuracy                           0.45       150\n",
            "   macro avg       0.43      0.44      0.42       150\n",
            "weighted avg       0.43      0.45      0.42       150\n",
            "\n",
            "roc_auc:0.4172008547008547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzLS7rHTp4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "bec9e8a2-3a1e-4dd5-9ad4-b6836f6c8c27"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "col_0   0   1\n",
              "row_0        \n",
              "0      50  28\n",
              "1      55  17"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8aeb2e61-239b-4770-887f-717857491039\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8aeb2e61-239b-4770-887f-717857491039')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8aeb2e61-239b-4770-887f-717857491039 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8aeb2e61-239b-4770-887f-717857491039');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o5Pco65c9rEA"
      },
      "execution_count": 100,
      "outputs": []
    }
  ]
}